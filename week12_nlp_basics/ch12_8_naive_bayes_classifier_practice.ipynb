{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bd7079-fa1d-4f26-90d3-f52af3d01b1e",
   "metadata": {},
   "source": [
    "# ch 12_8 naive bayes를 이용한 텍스트 분류\n",
    "\n",
    "이번 챕터에서는 scikit learn에 내장된 NaiveBayesClassifier를 이용해서 실제 텍스트를 분류해보고, 성능을 측정해보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f87f1-e418-4480-8951-5c4853941d6d",
   "metadata": {},
   "source": [
    "## 데이터 셋 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8954fc-2c39-4dee-b6a1-3d2d03a07c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./data/naver_reviews_train.csv\")\n",
    "test_df = pd.read_csv(\"./data/naver_reviews_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64210c9-3598-496a-9ada-32d9ee206e47",
   "metadata": {},
   "source": [
    "### 결측치 확인 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a504e0ad-0675-46ac-bbdf-3cee9255c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112041ee-c43f-4f0a-bcbe-45024ed773b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document    3\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533e985d-ff6c-4374-bd37-043fdc150c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573c10a5-dbc5-4700-898a-bdaee6635035",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126c609-d19f-4bd1-9d58-512b5994771d",
   "metadata": {},
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14d80a1-ff43-48aa-b2e9-0e10276d361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3822bb09-ed77-4b86-9708-be0eca5a5377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 149995/149995 [00:45<00:00, 3315.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 49997/49997 [00:16<00:00, 3061.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "train_df[\"tokens\"] = train_df[\"document\"].progress_apply(lambda x: komoran.morphs(x))\n",
    "test_df[\"tokens\"] = test_df[\"document\"].progress_apply(lambda x: komoran.morphs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04ac23-7df8-4057-a63a-cbfd5c2bc9b0",
   "metadata": {},
   "source": [
    "### CountVectorizer를 이용한 벡터화\n",
    "Naive Bayes를 학습시키기 위해서는 문서 내 특정 단어의 빈도 수를 세어주어야 합니다. 이를 CountVectorizer를 이용해서 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee48179-38f6-4e6f-81e1-8df329a5c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a922c54f-e454-481d-827d-f2b41950982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(train_df[\"tokens\"])\n",
    "x_train = vectorizer.transform(train_df[\"tokens\"])\n",
    "y_train = train_df[\"label\"]\n",
    "x_test = vectorizer.transform(test_df[\"tokens\"])\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd47242-d4db-4561-824b-f8338447005c",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier 학습\n",
    "\n",
    "scikit learn에 내장된 MultinomialNB를 이용하여 Naive Bayes Classifier를 학습시켜 보겠습니다. MultinomialNB를 사용하는 이유는 단어의 등장 빈도 수를 이용하여 분류하기 때문입니다. 먼저 학습시에 교차 검증으로 정확도를 측정하고, 전체 데이터 셋으로 다시 학습시킨 뒤, 테스트 셋에 대하여 정확도를 측정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d698e203-1db3-4d28-9573-62548217d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e025885d-30a7-4bde-b441-3730d48e8ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 정확도: [0.82666089 0.82946098 0.83222774 0.83076103 0.83149438]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "model = MultinomialNB()\n",
    "cross_val_scores = cross_val_score(model, x_train, y_train, cv=stratified_kfold)\n",
    "print(\"교차 검증 정확도:\", cross_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0788e0e7-63fa-4803-af2b-51ae6e1273ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eb7a0ee-23cb-4971-b047-29296e27a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정확도: 0.82406944416665\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"테스트 셋 정확도:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82bf3e-cb1c-40c5-9208-fa71ef3da2e6",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 챕터에서는 scikit learn에 내장된 MultinomialNB 클래스를 이용하여 텍스트 분류 모델을 학습시켜 보았습니다. 그 결과 82%로 상당히 준수한 성능이 나왔습니다. LSTM을 이용한 딥러닝 모델도 85% 정도 성능을 내는 것을 생각해보면 굉장히 가성비가 좋은 모델임을 알 수 있습니다. 베이즈 정리가 이렇게도 활용되는 구나 하는 점과 단순한 모델의 강력함을 꼭 기억하고 넘어갔으면 좋겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e12d1c-2975-475e-b250-516dad9f45ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
