{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7074b3fc-4f9e-40df-9b8c-26f8324f5b3b",
   "metadata": {},
   "source": [
    "# ch 20_4 langchain\n",
    "\n",
    "langchain은 LLM을 이용하여 애플리케이션을 만들 때 필요한 여러 기능들을 구현하여 제공하는 라이브러리입니다. 물론, langchain이 제공하는 기능들이 구현이 몹시 어려운 것들은 아니지만, 이를 적절히 활용하면 시간을 절약할 수 있습니다. langchain이 제공하는 주요 기능은 아래와 같습니다.\n",
    "\n",
    "- 대화 맥락 유지\n",
    "- 프롬프트 템플릿 관리\n",
    "- 검색 결과 등 배경 지식 추가\n",
    "\n",
    "이번 챕터에서는 langchain이 제공하는 기능들 중 대화 맥락 유지 기능을 사용하여 단순한 채팅을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1e78f-c9dc-44e3-b986-a9ccba4fb6cd",
   "metadata": {},
   "source": [
    "## 사전 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d6ab4-012f-4eb5-8a85-3e8a23c34e1e",
   "metadata": {},
   "source": [
    "### openAI 라이브러리 설치 및 토큰 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee7fed-fa63-4aaf-8da9-5e1ca3be58cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfd6084-a227-4d76-98ee-805c505d0069",
   "metadata": {},
   "source": [
    "### langchain 설치 및 openai 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad98eee-4a3a-4dc2-8b49-943d585f07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d82b7dc-58a5-4f4a-b174-2419578ffc49",
   "metadata": {},
   "source": [
    "## openai ChatCompletion API로 대화 나누기 \n",
    "\n",
    "chatGPT API를 사용하여 대화 맥락을 기록하려면 이전에 나눴던 대화를 함께 입력으로 넣어주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a2a1f-75a3-4039-a201-18d0706845b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "793c0e1c-bf7a-46ab-a5ac-1af74ec7c4f2",
   "metadata": {},
   "source": [
    "먼저 질문을 입력하여 messages에 추가한 뒤, chatGPT에 답변 생성을 요청해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a924df5-a36f-4cab-b7b4-58dfe1671f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06182249-1bfa-406c-b6b6-8463d6324889",
   "metadata": {},
   "source": [
    "대화의 맥락을 유지하기 위해서는 chatGPT의 답변을 messages에 추가해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0eabd-9e0a-4c4e-8ec7-4234a48501de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2eb1479-1e7b-44fa-855e-b9a4f001d65f",
   "metadata": {},
   "source": [
    "이제 대화의 맥락을 기억해야만 답변할 수 있는 질문을 던져보겠습니다. 여기서는 이전 대화에서 추천한 메뉴들 중 세번째 옵션에 대해서 추가 설명을 요청해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b598080-4576-4ae3-9f7a-88dc67296215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe54439d-eb17-408f-aa9a-eba65e91be67",
   "metadata": {},
   "source": [
    "chatGPT가 이전 대화 맥락을 기억하면서 추가 답변을 잘 생성한 것을 확인할 수 있습니다. 이처럼 대화의 맥락을 유지하기 위해서는 지금까지 나눈 대화를 잘 기록해두었다가, 요청을 보낼 때 보내주면 됩니다.\n",
    "\n",
    "그런데 여기서 만약 대화가 길어지면 어떻게 될까요? chatGPT는 한번에 요청으로 보낼 수 있는 토큰 수에 제한이 있습니다. 때문에 모든 대화 내용을 기록할 경우, 금세 토큰 수 제한에 걸리게 됩니다. 따라서 적절하게 대화 내용 중 중요한 내용들만 유지하는 것이 중요합니다. 이 때 사용할 수 있는 기능이 LangChain의 Memory 기능입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1e61c-0a7f-4282-8051-285eaab26d74",
   "metadata": {},
   "source": [
    "## Langchain Memory\n",
    "\n",
    "대화 맥락을 유지하기 위해서 취할 수 있는 조치들은 다음과 같습니다.\n",
    "\n",
    "- 최근 K개의 대화만 유지하기\n",
    "- 전체 대화 내용을 요약해서 유지하기\n",
    "- 최근 K개의 대화를 요약해서 유지하기\n",
    "\n",
    "한번 차근차근 어떻게 사용하는지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c8108-fc14-417a-ba2a-a50eaf008e56",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory\n",
    "\n",
    "ConversationBufferWindowMemory를 사용하면 이전 K개 만큼의 대화만 history에 저장할 수 있습니다. 바로 직전의 대화만 기억하도록 설정한 다음, 대화를 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353c797-932a-4eea-b46c-9315ab069ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee7d9c0-4ca9-4804-adab-5ea69ba0b612",
   "metadata": {},
   "source": [
    "langchain의 ConversationChain은 내부적으로 프롬프트 템플릿을 가지고 있습니다. 이를 이용해서 LLM에 요청을 보내고, 답변을 받아오는 방식으로 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2e528-6f91-4a7b-8cb6-2eb979664027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9abebf-fc62-4daa-9654-51ac7091ab94",
   "metadata": {},
   "source": [
    "대화를 진행해보겠습니다. 이전에 나눈 대화 내용은 history에 기록됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4986be-4347-48f0-acce-212307fc813d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f301ff03-7b8e-45b3-aca4-0f8f83966cab",
   "metadata": {},
   "source": [
    "ConversationBufferWindowMemory를 사용하면 이렇게 이전 K개의 대화를 그대로 유지할 수 있습니다. 용도에 맞게 k값을 조정하시면 됩니다. 하지만 이렇게 할 경우,  chatGPT가 긴 텍스트를 생성하게 될 경우 토큰 수가 순식간에 늘어난다는 한계점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2caa97-27ba-4a27-83e5-9cfba6ba45f1",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "이전 대화 내용을 통째로 기억해야만 할까요? 중요한 정보만 요약해서 저장하면 대화 맥락은 유지하면서 토큰 수는 절약할 수 있겠죠? ConversationSummaryMemory는 LLM을 이용해서 이전 대화 히스토리를 요약해서 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc633398-1491-4bc9-bec7-10e0b5ffa055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "769ad7d6-37d1-4463-80bd-d3d52dfb922e",
   "metadata": {},
   "source": [
    "대화를 진행할 수록 지금까지 나눈 대화가 요약되어서 history에 기록되는 것을 확인할 수 있습니다. 하지만 이 방식 역시 대화가 길어질 수록 토큰 수가 늘어나는 한계점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93793469-82f0-4c4d-988f-7b7184826798",
   "metadata": {},
   "source": [
    "### ConversationSummaryBufferMemory\n",
    "\n",
    "ConversationSummaryBufferMemory는 BufferWindow 방식과 Summary 방식을 섞은 기법입니다. 전체 대화에서 최근 m개의 토큰만 잘라서 요약한 다음, 이를 history에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd8672-a9e6-411e-a8fb-34c2333e49b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b581d80c-fa8d-4854-afac-06b2374207e2",
   "metadata": {},
   "source": [
    "## LangChain Streaming\n",
    "\n",
    "streaming 방식으로 대화를 생성해보겠습니다. llm 객체를 만들 때, streaming 옵션을 True로 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a4779-76f6-4804-82c6-98d4ee3ae144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3417d8b1-48cc-4a16-8726-16802df5a6b9",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 챕터에서는 chatGPT와 대화 맥락을 유지하면서 대화를 나누는 방법을 알아보았습니다. 그리고 langchain을 이용하여 대화 맥락은 유지하면서 토큰 수를 아낄 수 있는 방법을 알아보았습니다. 이를 서비스에 적절히 연결하면 chatbot을 구현할 수 있습니다. 다음 챕터에서는 streamlit과 langchain을 사용하여 간단한 chatbot 서비스를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5568af5-4b80-4689-99ea-72bc997cb143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
