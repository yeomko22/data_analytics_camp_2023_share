from datetime import datetime, timezone
from typing import List, Generator

import openai
import pinecone
import streamlit as st
from google.cloud import translate
from google.oauth2.service_account import Credentials
from openai.openai_object import OpenAIObject

st.set_page_config(
    page_title="worms book",
    page_icon="ğŸ“–",
)


@st.cache_resource
def init_google_translation_connection():
    credentials = Credentials.from_service_account_info(st.secrets.GOOGLE)
    return translate.TranslationServiceClient(credentials=credentials)


@st.cache_resource
def init_pinecone_connection():
    pinecone.init(
        api_key=st.secrets["PINECONE_KEY"],
        environment=st.secrets["PINECONE_REGION"]
    )
    index = pinecone.Index('bookstore')
    return index


def get_embedding(query):
    response = openai.Embedding.create(input=[query], model="text-embedding-ada-002")
    return response["data"][0]["embedding"]


def get_translation(query):
    parent = f"projects/{st.secrets.PROJECTID}/locations/global"
    response = google_translate_client.translate_text(
        request={
            "parent": parent,
            "contents": [query],
            "mime_type": "text/plain",
            "source_language_code": "ko",
            "target_language_code": "en-US",
        }
    )
    translations = response.translations
    return translations[0].translated_text


google_translate_client = init_google_translation_connection()
pinecone_index = init_pinecone_connection()
openai.api_key = st.secrets.OPENAI_TOKEN
openai_model_version = "gpt-3.5-turbo-0613"

st.title("ì›œì¦ˆì˜ ì±…ë°© ğŸ“–ğŸ›")
st.image("./images/banner.png")


def recommend(query_embedding):
    results = pinecone_index.query(
        vector=query_embedding,
        top_k=3,
        include_metadata=True,
    )
    matches = results["matches"]
    return [x["metadata"] for x in matches]


def generate_prompt(query):
    prompt = f"""
ìœ ì €ê°€ ì½ê³  ì‹¶ì€ ì±…ì— ëŒ€í•œ ë¬˜ì‚¬ì™€ ì´ì— ëŒ€í•œ ì¶”ì²œ ê²°ê³¼ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.
ìœ ì €ì˜ ì…ë ¥ê³¼ ê° ì¶”ì²œ ê²°ê³¼ ì±…ì˜ ì œëª©, ì €ì, ì†Œê°œ ë“±ì„ ì°¸ê³ í•˜ì—¬ ì¶”ì²œì‚¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
ë‹¹ì‹ ì— ëŒ€í•œ ì†Œê°œë¥¼ ë¨¼ì € í•˜ê³ , ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì¤‘ê°„ ì¤‘ê°„ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

---
ìœ ì € ì…ë ¥: {query}

ì¶”ì²œ ê²°ê³¼ 1
ì œëª©: {items[0]['title']}
ì €ì: {items[0]['authors']}
ì±…ì†Œê°œ: {items[0]['summary']}

ì¶”ì²œ ê²°ê³¼ 2
ì œëª©: {items[1]['title']}
ì €ì: {items[1]['authors']}
ì±…ì†Œê°œ: {items[1]['summary']}

ì¶”ì²œ ê²°ê³¼ 3
ì œëª©: {items[2]['title']}
ì €ì: {items[2]['authors']}
ì±…ì†Œê°œ: {items[2]['summary']}
---
"""
    return prompt


def request_chat_completion(prompt):
    response = openai.ChatCompletion.create(
        model=openai_model_version,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì±…ì„ ì¶”ì²œí•´ì£¼ëŠ” ì±…ë°©ì§€ê¸°, ì›œì¦ˆì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        stream=True
    )
    return response


def get_author_title(item):
    author = item["authors"]
    title = item["title"]
    author_list = author.split(",")
    if len(author_list) > 1:
        author = f"{author_list[0]} ì™¸ {len(author_list) - 1}ì¸"
    return f"{author} - {title}"


def process_recommend_results(items):
    st.markdown("**ì¶”ì²œê²°ê³¼ ğŸ (ì—´ ìˆ˜ ìˆì–´ìš”!)**")
    for i, item in enumerate(items):
        with st.expander(f"#{i+1} {get_author_title(item)}"):
            st.header(item["title"])
            st.write(f"**{item['authors']}** | {item['publisher']} | {item['published_at']} | [yes24]({item['url']})")
            col1, col2 = st.columns([0.25, 0.75], gap="medium")
            with col1:
                st.image(item["img_url"])
            with col2:
                st.write(item["summary"])


def process_generated_text(streaming_resp: Generator[OpenAIObject, None, None]) -> str:
    st.markdown("**ì›œì¦ˆì˜ ì¶”ì²œì‚¬ âœï¸**")
    report = []
    res_box = st.empty()
    for resp in streaming_resp:
        delta = resp.choices[0]["delta"]
        if "content" in delta:
            report.append(delta["content"])
            res_box.markdown("".join(report).strip())
        else:
            break
    result = "".join(report).strip()
    return result


with st.form("form"):
    query = st.text_input(
        label="ì½ê³  ì‹¶ì€ ì±…ì„ ë¬˜ì‚¬í•˜ë©´ AIê°€ ì¶”ì²œí•´ì¤ë‹ˆë‹¤ğŸ’¡",
        placeholder="ex) ì¢€ë¹„ì™€ ê°€ì¡±ì• ë¥¼ ë‹¤ë£¬ ì´ì•¼ê¸°"
    )
    submitted = st.form_submit_button("ì œì¶œ")
if submitted:
    if not query:
        st.error("ì½ê³  ì‹¶ì€ ì±… ë¬˜ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”")
    else:
        with st.spinner("ì›œì¦ˆê°€ ì±…ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
            translated_query = get_translation(query)
            query_embedding = get_embedding(translated_query)
            items = recommend(query_embedding)
        process_recommend_results(items)

        with st.spinner("ì›œì¦ˆê°€ ì¶”ì²œì‚¬ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤..."):
            prompt = generate_prompt(query, items)
            streaming_resp = request_chat_completion(prompt)
        process_generated_text(streaming_resp)
