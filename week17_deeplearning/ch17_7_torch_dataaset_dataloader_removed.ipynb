{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ceba43-ef68-424a-9522-1252be448535",
   "metadata": {},
   "source": [
    "# ch17_7 torch dataloader\n",
    "\n",
    "이번 챕터에서는 본격적으로 딥러닝 모델링에 들어가기 앞서서, torch에서 딥러닝 모델 학습을 위해 대량의 데이터 셋을 처리하는 기법에 대해서 알아보겠습니다.\n",
    "\n",
    "지금까지는 모든 데이터 셋이 메모리에 한번에 올라올 수 있는 사이즈가 작은 데이터 셋들이었습니다. 그런데 몇만장의 이미지로 구성된 데이터 셋은 어떨까요? 혹은 수십GB에 달하는 텍스트 데이터라면 어떨까요? 이들을 한번에 메모리에 올리기 보단, 일정한 단위로 메모리에 올려서 모델 학습을 진행하고, 다시 다음 단위를 메모리에 올리는 것이 좋겠죠? torch에서 이런 기능을 제공해주는 기능이 dataset과 dataloader입니다.\n",
    "\n",
    "데이터 셋 링크: https://www.kaggle.com/datasets/tongpython/cat-and-dog  \n",
    "참고 자료: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf80a5-755b-48f2-b2db-749a3bee2f0e",
   "metadata": {},
   "source": [
    "## 데이터 셋 폴더 구조\n",
    "\n",
    "실습을 위해 사용할 데이터 셋은 강아지와 고양이 이미지 데이터 셋입니다. 폴더 구조는 아래와 같습니다. 먼저 train과 test로 나뉜 뒤, 그 아래에 고양이 이미지와 강아지 이미지들을 담은 폴더가 위치합니다. 그리고 labels에는 각 이미지 파일 경로와 라벨이 담겨있습니다. 라벨은 고양이는 0, 강아지는 1입니다.\n",
    "\n",
    "```\n",
    "cats_and_dogs\n",
    "├── test\n",
    "│   ├── cats\n",
    "│   ├── dogs\n",
    "│   └── label.csv\n",
    "└── train\n",
    "    ├── cats\n",
    "    ├── dogs\n",
    "    └── label.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3387e5-3e7b-418c-aa8f-c015748fb39a",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### CustomDataset 정의\n",
    "torch에서 데이터 셋을 다루려면 먼저 Dataset 클래스를 상속 받은 Custom Dataset이 있어야 합니다. Custom Dataset은 데이터 샘플 하나를 어떻게 읽어와서 어떻게 처리할 지를 정의하는 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f703e-c155-49f3-bae5-2f5726ad77ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76dfab5-1861-43b6-acd0-53199d526cf8",
   "metadata": {},
   "source": [
    "이렇게 만든 데이터 셋은 인덱스로 접근이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d3a66-97a8-4e99-ac05-e50aa9cf955b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dab8ec7b-9e93-4614-9183-098695d068aa",
   "metadata": {},
   "source": [
    "실제로 이미지를 잘 읽어왔는지 플랏을 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279187b-d917-4636-abde-fc5f3131af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50d347b6-41f7-4bf9-aeb6-f050791042d8",
   "metadata": {},
   "source": [
    "### transform\n",
    "\n",
    "현재는 입력 이미지의 크기가 제각각입니다. 이 경우, 모델의 구조와 학습 방법이 상당히 까다로워집니다. 때문에 입력으로 들어오는 이미지의 크기를 고정하는 전처리를 취해주겠습니다. \n",
    "\n",
    "먼저 가로, 세로 중 더 짧은 쪽의 크기를 256으로 조정하겠습니다. 그 다음, 중심을 기준으로 (256, 256) 크기로 크롭해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c878b-7723-41c1-a590-262a6c678088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03827617-1642-4228-aa32-01c52652af8d",
   "metadata": {},
   "source": [
    "### data augmentation\n",
    "\n",
    "자 그런데 이미지 데이터의 경우, 노이즈에 굉장히 취약합니다. 예를들어 고양이의 자세, 회전, 조명, 위치 등의 변수가 너무 많습니다. 데이터 셋이 아무리 많이 주어진 다고 하더라도 이러한 변수들을 모두 포함할 수는 없습니다. 따라서 데이터 셋에 의도적으로 변형을 가해서 부풀려주는 data augmentation 기법을 사용할 수 있습니다.\n",
    "\n",
    "torch transforms에 내장되어 있는 함수를 사용하면 손쉽게 data augmentation을 구현할 수 있습니다. 무작위로 크롭하는 RandomCrop, 무작위로 좌우를 반전시켜주는 RandomHorizontalFlip, 주어진 범위 내에서 무작위로 회전을 주는 RandomRotation을 적용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb826e-0ede-47b4-99bb-bf2bb0314abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21867a8-2542-474c-b78f-9bdcc8fa44ad",
   "metadata": {},
   "source": [
    "이렇게 해서 입력으로 들어오는 이미지의 크기는 고정하고, 여러 변형을 가해줄 수 있게 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21c87b-cf6e-4c9e-b9e2-6f6e3e4c5fc6",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "전체 데이터 셋은 고양이 4000장, 강아지 4000장으로 구성되어 있습니다. 하지만 이를 한꺼번에 메모리에 올려서 모델을 학습시키는 것은 메모리와 CPU, GPU에 엄청난 부담이 갑니다. 때문에 일정한 크기로 데이터 셋을 불러와서 모델을 학습시켜야 합니다. 여기서 일정한 크기를 배치라고 부르고, 데이터를 배치 단위로 읽어오는 역할은 DataLoader가 수행합니다.\n",
    "\n",
    "dataloader를 만들어보고, batch로 불러온 이미지 텐서를 시각화 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a13959-9cf4-4a79-9650-1fdf7a9f2f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50aa566e-6028-46d0-bdb7-0a1aa620b128",
   "metadata": {},
   "source": [
    "시각화를 해보면 개와 고양이가 잘 섞여서 불러와 지는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae0506-1fed-42db-899f-751fc150eac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97de1b54-a611-4ee7-a44b-bebc2317dc29",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "이렇게 직접 수집한 데이터 셋으로 torch Dataset과 Dataloader를 만들어서 사용할 수도 있지만, 이미 만들어져 있는 데이터 셋을 그대로 불러와서 사용할 수도 있습니다. 딥러닝 입문 시에 가장 많이 사용되는 MINIST 데이터 셋을 한번 로딩해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc64334-7c4c-4a82-b00d-7ca9973e99d7",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "\n",
    "MNIST dataset은 0부터 9 사이 숫자들의 손글씨 이미지를 모아놓은 데이터 셋입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352062c-e107-4cc3-8f7e-97c9c4079310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60161596-f0f7-4a3d-a0dc-252f4616d15a",
   "metadata": {},
   "source": [
    "이렇게 불러온 데이터 셋을 데이터 로더로 만들어서 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30aec0-8071-4f72-a1f9-6cb29320817f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4033e240-dbc7-4e45-80e9-7426a679163f",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이번 챕터에서는 torch dataset과 dataloader를 다루는 법에 대해서 알아보았습니다. 그리고 데이터 셋에 무작위 적으로 조작을 가해, 데이터 셋의 크기를 부풀리는 data augmentation 기법에 대해서 알아보았습니다. 다음 챕터에서는 본격적으로 딥러닝 모델을 이용하여 이미지 분류 모델을 학습시켜 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6af8b9-7b71-4c81-98a7-e7f1e08a47e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
