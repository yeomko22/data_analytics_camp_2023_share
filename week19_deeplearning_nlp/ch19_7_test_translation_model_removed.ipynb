{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1hab8sr-uxnXWfwhVUMynV8S4x9sBg0yG",
      "authorship_tag": "ABX9TyNnDeGt/nEyAX+1gWbKrfCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeomko22/data_analytics_camp_2023_share/blob/main/week19_deeplearning_nlp/ch19_7_test_translation_model_removed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch19_7 번역 모델 성능 평가하기\n",
        "\n",
        "이번 챕터에서는 번역 모델의 성능을 평가하는 방법에 대해서 알아보겠습니다.\n",
        "\n",
        "\n",
        "- 이 튜토리얼에서는 이전 시간에 학습시킨 seq2seq 모델로 직접 번역을 돌려보고 성능 평가를 해봅니다.\n",
        "- greedy decoding과 beam search를 직접 구현해봅니다."
      ],
      "metadata": {
        "id": "ipbiq2-ZitYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사전 작업"
      ],
      "metadata": {
        "id": "mRUtTFzJIy5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 디바이스 설정"
      ],
      "metadata": {
        "id": "LU5JuAM6Lv95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rsQckVt-Lysz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 셋 불러오기"
      ],
      "metadata": {
        "id": "lnx2KP85I1Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv(\"./drive/MyDrive/dscamp_2023/translation_test.csv\")"
      ],
      "metadata": {
        "id": "OtD1h5WiI4kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cJHokBq2I_M5",
        "outputId": "7d8fae4d-0646-4c29-a12a-6267798b8125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   kor  \\\n",
              "0                   정말? 그래서 좋은 시간을 보냈니? 맛있는 것도 많이 먹었니?   \n",
              "1       만약 우리의 인생이 한낱 꿈에 불과하다면, 왜 우리는 모두 이렇게 욕심이 많을까요?   \n",
              "2    우리는 공항에서만 무료 와이파이를 쓸 수 있어서 게스트하우스 가는 길을 미리 찾아놨어요.   \n",
              "3                    그곳에 한국에서 분차를 가장 맛있게 먹을 수 있는 곳입니다.   \n",
              "4                   나는 그림을 잘 그리진 못하지만 그림 그리는 것을 좋아합니다.   \n",
              "..                                                 ...   \n",
              "995                                내가 보낸 우편물을 확인해 봤어요?   \n",
              "996                              나는 바로 유치원으로 취직을 했습니다.   \n",
              "997                                 고맙지만 도와주시지 않아도 돼요.   \n",
              "998                        오늘 우리 3명은 커피숍을 소개하도록 하겠습니다.   \n",
              "999                          칩은 쓰레기를 버릴 때마다 1개씩 부착합니다.   \n",
              "\n",
              "                                                   eng  \n",
              "0    really? so did you have a good time? did you e...  \n",
              "1    if our life is but a dream, why do we have an ...  \n",
              "2    as we could only use free wifi at the airport,...  \n",
              "3    the place where we can enjoy the bun cha the m...  \n",
              "4           i can't draw very well but i like to draw.  \n",
              "..                                                 ...  \n",
              "995                     did you check the mail i sent?  \n",
              "996         i got a job at a kindergarten immediately.  \n",
              "997                   thank you, but i dont need help.  \n",
              "998  we, three members, will introduce coffee shops...  \n",
              "999  stick one chip each time you throw the waste a...  \n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60b3d169-20a2-4ee6-88d9-f5a0565dd72f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kor</th>\n",
              "      <th>eng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정말? 그래서 좋은 시간을 보냈니? 맛있는 것도 많이 먹었니?</td>\n",
              "      <td>really? so did you have a good time? did you e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>만약 우리의 인생이 한낱 꿈에 불과하다면, 왜 우리는 모두 이렇게 욕심이 많을까요?</td>\n",
              "      <td>if our life is but a dream, why do we have an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>우리는 공항에서만 무료 와이파이를 쓸 수 있어서 게스트하우스 가는 길을 미리 찾아놨어요.</td>\n",
              "      <td>as we could only use free wifi at the airport,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그곳에 한국에서 분차를 가장 맛있게 먹을 수 있는 곳입니다.</td>\n",
              "      <td>the place where we can enjoy the bun cha the m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>나는 그림을 잘 그리진 못하지만 그림 그리는 것을 좋아합니다.</td>\n",
              "      <td>i can't draw very well but i like to draw.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>내가 보낸 우편물을 확인해 봤어요?</td>\n",
              "      <td>did you check the mail i sent?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>나는 바로 유치원으로 취직을 했습니다.</td>\n",
              "      <td>i got a job at a kindergarten immediately.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>고맙지만 도와주시지 않아도 돼요.</td>\n",
              "      <td>thank you, but i dont need help.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>오늘 우리 3명은 커피숍을 소개하도록 하겠습니다.</td>\n",
              "      <td>we, three members, will introduce coffee shops...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>칩은 쓰레기를 버릴 때마다 1개씩 부착합니다.</td>\n",
              "      <td>stick one chip each time you throw the waste a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60b3d169-20a2-4ee6-88d9-f5a0565dd72f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60b3d169-20a2-4ee6-88d9-f5a0565dd72f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60b3d169-20a2-4ee6-88d9-f5a0565dd72f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35192ef0-dffc-488f-bbfe-45eb547537d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35192ef0-dffc-488f-bbfe-45eb547537d1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35192ef0-dffc-488f-bbfe-45eb547537d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tokenizer 불러오기 및 tokenize 함수 작성"
      ],
      "metadata": {
        "id": "tz6Crp_CJSQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "\n",
        "\n",
        "kor_tokenizer = Tokenizer.from_file(\"./drive/MyDrive/dscamp_2023/translation_kor_tokenizer.json\")\n",
        "eng_tokenizer = Tokenizer.from_file(\"./drive/MyDrive/dscamp_2023/translation_eng_tokenizer.json\")"
      ],
      "metadata": {
        "id": "UrIJt5MyJVfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = kor_tokenizer.get_vocab()\n",
        "pad_token = vocabs[\"[PAD]\"]\n",
        "sos_token = vocabs[\"[SOS]\"]\n",
        "eos_token = vocabs[\"[EOS]\"]"
      ],
      "metadata": {
        "id": "N8MAbCN6LKPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 256\n",
        "\n",
        "def tokenize(text, is_korean=True):\n",
        "    if is_korean:\n",
        "        tokens = kor_tokenizer.encode(text).ids\n",
        "    else:\n",
        "        tokens = eng_tokenizer.encode(text).ids\n",
        "    tokens = tokens[:MAX_TOKENS]\n",
        "    token_tensor = torch.tensor(tokens, dtype=torch.long)\n",
        "    return token_tensor"
      ],
      "metadata": {
        "id": "cQto8zWuJcBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 불러오기"
      ],
      "metadata": {
        "id": "xwAcfhBdJuZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, bidirectional):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=0.5,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        packed_embedded = pack_padded_sequence(embedded, lengths, enforce_sorted=False)\n",
        "        padded_outputs, hidden = self.rnn(packed_embedded)\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "            hidden = hidden.unsqueeze(0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "SVhx9SZGJxdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=0.5,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, lengths, hidden):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        packed_embedded = pack_padded_sequence(embedded, lengths, enforce_sorted=False)\n",
        "\n",
        "        # rnn 호출 시에 encoder로부터 전달받은 hidden, cell을 넣어주면 됩니다.\n",
        "        packed_output, hidden = self.rnn(packed_embedded, hidden)\n",
        "        outputs, output_lengths = pad_packed_sequence(packed_output)\n",
        "        prediction = self.dropout(self.fc(outputs))\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "K5xdjV-1J_Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src_padded, src_lengths, tar_in_padded, tar_lengths):\n",
        "        hidden = self.encoder(src_padded, src_lengths)\n",
        "        prediction, hidden = self.decoder(tar_in_padded, tar_lengths, hidden)\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "R7rUDNYpKCD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 8000\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_UNITS = 256\n",
        "EMBED_MAX_NORM = 1\n",
        "NUM_LAYERS = 1\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = True"
      ],
      "metadata": {
        "id": "rVc3HI5tKI-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_UNITS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    bidirectional=BIDIRECTIONAL\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPHxJ-lMKEgW",
        "outputId": "5ae67617-62be-4bac-cf8b-693607319bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_UNITS,\n",
        "    num_layers=NUM_LAYERS,\n",
        ")"
      ],
      "metadata": {
        "id": "ypcPtQDGKM35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(encoder, decoder)"
      ],
      "metadata": {
        "id": "siMRpI8qKR61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_path = \"./drive/MyDrive/dscamp_2023/translation_weight.pth\"\n",
        "weight = torch.load(weight_path)"
      ],
      "metadata": {
        "id": "FKmWVDb2Kdxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnXlGWR6K3Pu",
        "outputId": "812c9176-ff08-49d1-c142-22babe888ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "jc0rn30TL4Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1RqFTzKWrs",
        "outputId": "ed9a74f4-b666-4479-df4a-bb7e220e9656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53tn6pJOKUiC",
        "outputId": "e8116636-8f91-4e07-e492-dd9ac376446c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Seq2Seq                                  --\n",
              "├─Encoder: 1-1                           --\n",
              "│    └─Embedding: 2-1                    2,048,000\n",
              "│    └─GRU: 2-2                          789,504\n",
              "│    └─Dropout: 2-3                      --\n",
              "│    └─Linear: 2-4                       131,328\n",
              "├─Decoder: 1-2                           --\n",
              "│    └─Embedding: 2-5                    2,048,000\n",
              "│    └─GRU: 2-6                          394,752\n",
              "│    └─Linear: 2-7                       2,056,000\n",
              "│    └─Dropout: 2-8                      --\n",
              "=================================================================\n",
              "Total params: 7,467,584\n",
              "Trainable params: 7,467,584\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy Decoding"
      ],
      "metadata": {
        "id": "OZDrKWPQK_KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 30\n",
        "\n",
        "def greedy_decoding(model, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenize(sentence, is_korean=True)\n",
        "    src_in = tokens.unsqueeze(-1).to(device)\n",
        "    src_lengths = [len(tokens)]\n",
        "    tar_in = torch.tensor([[sos_token]], dtype=torch.long).to(device)\n",
        "    tar_lengths = [1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden = model.encoder(src_in, src_lengths)\n",
        "        results = []\n",
        "        for i in range(MAX_SEQUENCE_LENGTH):\n",
        "            prediction, hidden = model.decoder(tar_in, tar_lengths, hidden)\n",
        "            # sequence length, batch size 모두 1이므로 의미 없는 차원 제거\n",
        "            prediction = prediction.squeeze()\n",
        "            # top1 예측 결과 저장 및 EOS 토큰일 경우 인퍼런스 중지\n",
        "            top1 = prediction.argmax()\n",
        "            results.append(top1.item())\n",
        "            if top1 == eos_token:\n",
        "                break\n",
        "            # 이전 시점의 출력값을 다음 시점의 입력 값으로 사용\n",
        "            tar_in = torch.tensor([[top1]], dtype=torch.long).to(device)\n",
        "    translated = eng_tokenizer.decode(results)\n",
        "    return translated"
      ],
      "metadata": {
        "id": "oICtdclVLBNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decoding(model, \"만나서 반갑고, 앞으로 잘부탁한다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "82aA3YJBLor_",
        "outputId": "9113cd72-7f45-45cd-c050-8816323fbb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"nice to meet you , and i ' m glad to meet you !\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 번역 모델 성능 측정\n",
        "\n",
        "번역 모델의 성능은 단순히 accuracy로 평가할 수 없습니다. 하나의 문장이 여러 문장으로 번역될 수 있고, 어순이 조금 달라지더라도 맞는 번역일 수 있기 때문입니다. 예를 들어보겠습니다.\n",
        "\n",
        "- 예시 입력: 만나서 반갑습니다.\n",
        "- 라벨: nice to meet you.\n",
        "- 번역 1: nice to meet you.\n",
        "- 번역 2: I'm glad to meet you.\n",
        "\n",
        "번역 1과 2 모두 맞는 번역임에도 불구하고 라벨과 비교해보면 번역 2는 완전히 잘못된 번역이라는 결과가 나옵니다. 이러한 번역 테스크의 특징을 잘 고려해주는 것이 bleu score입니다. bleu score의 세부적인 내용이 궁금하신 분들은 아래 문서를 참고해주세요.\n",
        "\n",
        "https://wikidocs.net/31695"
      ],
      "metadata": {
        "id": "fzXgor4PMK_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "bleu score를 측정할 때에는 보통 시퀀스의 길이에 따라서 score를 측정한 다음, 이를 그래프로 시각화 합니다. 예를들어 길이가 20 이하인 문장들만 번역한 결과 정확도를 측정하고, 30 이하인 문장들 번역 정확도를 측정하는 식입니다.\n",
        "\n",
        "시퀀스 길이를 변경해가며, bleu score를 측정해보겠습니다."
      ],
      "metadata": {
        "id": "sYiuiHJANd75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터 셋 번역\n",
        "\n",
        "greedy decoding 방식으로 테스트 데이터 셋을 번역해서 결과를 기록해보겠습니다."
      ],
      "metadata": {
        "id": "apRP_RoYN0yR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-NUkWn9Egyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bleu Score 계산\n",
        "\n",
        "토큰 길이 수에 따른 blue_score 계산 후, 플랏을 그려보겠습니다."
      ],
      "metadata": {
        "id": "omWhRDKQDQ01"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n8rJ0E6TElyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "\n",
        "이번 챕터에서는 기계 번역 모델의 성능을 측정하는 bleu score에 대해서 알아보았습니다. 이 외에 자연어 처리 분야에는 모델의 성능을 측정하는 지표들이 다양하게 존재합니다. 모델과 데이터에 맞게 지표를 선택한다는 점만 기억하고 넘어가겠습니다."
      ],
      "metadata": {
        "id": "jKdMz8-QP49u"
      }
    }
  ]
}